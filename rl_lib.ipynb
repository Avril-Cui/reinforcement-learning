{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RLlib\n",
    "- Offering scalability as RL applications can be compute-intensive and need to scale-out onto a cluster\n",
    "- Unified API\n",
    "- Contained in Ray\n",
    "### Ray\n",
    "- Parallelism and scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "1. A RL environment (e.g. CartPole-v1)\n",
    "2. A RL algorithm to learn in that environment (e.g. Proximal Policy Optimization (PPO))\n",
    "3. Conguration (algorithm, experiment, environment config, etc.)\n",
    "3. Experiment runner (tune)\n",
    "    - Iterating training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "CHECKPOINT_ROOT = \"tmp/ppo/taxi\"\n",
    "shutil.rmtree(CHECKPOINT_ROOT, ignore_errors=True, onerror=None) # clean up old runs\n",
    "ray_results = \"/results\"\n",
    "shutil.rmtree(ray_results, ignore_errors=True, onerror=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 22:17:53,801\tINFO worker.py:1807 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:568: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-11-04 22:17:57,545\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evaluation': {'env_runners': {'episode_reward_max': -477.0, 'episode_reward_min': -803.0, 'episode_reward_mean': -643.0, 'episode_len_mean': 191.8, 'episode_media': {}, 'episodes_timesteps_total': 1918, 'policy_reward_min': {'default_policy': -803.0}, 'policy_reward_max': {'default_policy': -477.0}, 'policy_reward_mean': {'default_policy': -643.0}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-713.0, -569.0, -564.0, -477.0, -803.0, -623.0, -605.0, -722.0, -596.0, -758.0], 'episode_lengths': [200, 200, 171, 147, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-713.0, -569.0, -564.0, -477.0, -803.0, -623.0, -605.0, -722.0, -596.0, -758.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.07706597921064337, 'mean_inference_ms': 0.26600531080602796, 'mean_action_processing_ms': 0.030074783015089653, 'mean_env_wait_ms': 0.015533858751989765, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0034928321838378906, 'StateBufferConnector_ms': 0.0011658668518066406, 'ViewRequirementAgentConnector_ms': 0.026538372039794922}, 'num_episodes': 10, 'episode_return_max': -477.0, 'episode_return_min': -803.0, 'episode_return_mean': -643.0, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 1918, 'num_env_steps_sampled_this_iter': 1918, 'timesteps_this_iter': 1918, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.13909831530945274, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.923288517613564, 'policy_loss': -0.011716101223462692, 'vf_loss': 9.933589402065483, 'vf_explained_var': -0.00027873387900731895, 'kl': 0.007075994578250918, 'entropy': 1.7847866981260239, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 465.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000, 'num_env_steps_sampled_for_evaluation_this_iter': 1918}, 'env_runners': {'episode_reward_max': -659.0, 'episode_reward_min': -857.0, 'episode_reward_mean': -787.25, 'episode_len_mean': 200.0, 'episode_media': {}, 'episodes_timesteps_total': 4000, 'policy_reward_min': {'default_policy': -857.0}, 'policy_reward_max': {'default_policy': -659.0}, 'policy_reward_mean': {'default_policy': -787.25}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-758.0, -830.0, -758.0, -821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-758.0, -830.0, -758.0, -821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08743015424660718, 'mean_inference_ms': 0.27449711271073446, 'mean_action_processing_ms': 0.03137104753134907, 'mean_env_wait_ms': 0.01615848855815012, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0037610530853271484, 'StateBufferConnector_ms': 0.0011467933654785156, 'ViewRequirementAgentConnector_ms': 0.027211904525756836}, 'num_episodes': 20, 'episode_return_max': -659.0, 'episode_return_min': -857.0, 'episode_return_mean': -787.25, 'episodes_this_iter': 20}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 1168.8910517968063, 'num_env_steps_trained_throughput_per_sec': 1168.8910517968063, 'timesteps_total': 4000, 'num_env_steps_sampled_lifetime': 4000, 'num_agent_steps_sampled_lifetime': 4000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 4000, 'timers': {'training_iteration_time_ms': 3422.054, 'restore_workers_time_ms': 0.01, 'training_step_time_ms': 3422.032, 'sample_time_ms': 851.026, 'load_time_ms': 0.124, 'load_throughput': 32263876.923, 'learn_time_ms': 2567.73, 'learn_throughput': 1557.796, 'synch_weights_time_ms': 2.976, 'restore_eval_workers_time_ms': 0.004, 'evaluation_iteration_time_ms': 756.901, 'evaluation_iteration_throughput': 2534.017}, 'counters': {'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000, 'num_env_steps_sampled_for_evaluation_this_iter': 1918}, 'done': False, 'training_iteration': 1, 'trial_id': 'default', 'date': '2024-11-04_22-18-01', 'timestamp': 1730776681, 'time_this_iter_s': 4.180715084075928, 'time_total_s': 4.180715084075928, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 4.180715084075928, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 26.349999999999998, 'ram_util_percent': 55.06666666666667}}\n",
      "{'evaluation': {'env_runners': {'episode_reward_max': -557.0, 'episode_reward_min': -857.0, 'episode_reward_mean': -694.7, 'episode_len_mean': 198.2, 'episode_media': {}, 'episodes_timesteps_total': 1982, 'policy_reward_min': {'default_policy': -857.0}, 'policy_reward_max': {'default_policy': -557.0}, 'policy_reward_mean': {'default_policy': -694.7}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-623.0, -812.0, -767.0, -857.0, -578.0, -803.0, -605.0, -677.0, -557.0, -668.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 182, 200], 'policy_default_policy_reward': [-623.0, -812.0, -767.0, -857.0, -578.0, -803.0, -605.0, -677.0, -557.0, -668.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.07766474518706266, 'mean_inference_ms': 0.2689163552220434, 'mean_action_processing_ms': 0.030419301509979412, 'mean_env_wait_ms': 0.015747299624601717, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.003693103790283203, 'StateBufferConnector_ms': 0.001220703125, 'ViewRequirementAgentConnector_ms': 0.02805948257446289}, 'num_episodes': 10, 'episode_return_max': -557.0, 'episode_return_min': -857.0, 'episode_return_mean': -694.7, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 1982, 'num_env_steps_sampled_this_iter': 1982, 'timesteps_this_iter': 1982, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2769835905442315, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.859454168299193, 'policy_loss': -0.030529154695930982, 'vf_loss': 9.88715993614607, 'vf_explained_var': -0.0001750550603353849, 'kl': 0.014117042088829882, 'entropy': 1.7556685340019964, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 1395.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000, 'num_env_steps_sampled_for_evaluation_this_iter': 1982}, 'env_runners': {'episode_reward_max': -273.0, 'episode_reward_min': -857.0, 'episode_reward_mean': -745.725, 'episode_len_mean': 196.275, 'episode_media': {}, 'episodes_timesteps_total': 7851, 'policy_reward_min': {'default_policy': -857.0}, 'policy_reward_max': {'default_policy': -273.0}, 'policy_reward_mean': {'default_policy': -745.725}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-758.0, -830.0, -758.0, -821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0, -803.0, -273.0, -821.0, -857.0, -794.0, -641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 123, 200, 200, 200, 200, 200, 200, 139, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 189], 'policy_default_policy_reward': [-758.0, -830.0, -758.0, -821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0, -803.0, -273.0, -821.0, -857.0, -794.0, -641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08739430233271778, 'mean_inference_ms': 0.2746035794579595, 'mean_action_processing_ms': 0.031370990316555436, 'mean_env_wait_ms': 0.016176671583358913, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0037306547164916992, 'StateBufferConnector_ms': 0.001150965690612793, 'ViewRequirementAgentConnector_ms': 0.02749025821685791}, 'num_episodes': 20, 'episode_return_max': -273.0, 'episode_return_min': -857.0, 'episode_return_mean': -745.725, 'episodes_this_iter': 20}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 1194.652168578724, 'num_env_steps_trained_throughput_per_sec': 1194.652168578724, 'timesteps_total': 8000, 'num_env_steps_sampled_lifetime': 8000, 'num_agent_steps_sampled_lifetime': 8000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 8000, 'timers': {'training_iteration_time_ms': 3385.156, 'restore_workers_time_ms': 0.007, 'training_step_time_ms': 3385.139, 'sample_time_ms': 849.729, 'load_time_ms': 0.749, 'load_throughput': 5343913.362, 'learn_time_ms': 2531.542, 'learn_throughput': 1580.065, 'synch_weights_time_ms': 2.937, 'restore_eval_workers_time_ms': 0.005, 'evaluation_iteration_time_ms': 776.842, 'evaluation_iteration_throughput': 2510.163}, 'counters': {'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000, 'num_env_steps_sampled_for_evaluation_this_iter': 1982}, 'done': False, 'training_iteration': 2, 'trial_id': 'default', 'date': '2024-11-04_22-18-05', 'timestamp': 1730776685, 'time_this_iter_s': 4.146434783935547, 'time_total_s': 8.327149868011475, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 8.327149868011475, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 43.75, 'ram_util_percent': 55.18333333333333}}\n",
      "{'evaluation': {'env_runners': {'episode_reward_max': -533.0, 'episode_reward_min': -767.0, 'episode_reward_mean': -651.8, 'episode_len_mean': 200.0, 'episode_media': {}, 'episodes_timesteps_total': 2000, 'policy_reward_min': {'default_policy': -767.0}, 'policy_reward_max': {'default_policy': -533.0}, 'policy_reward_mean': {'default_policy': -651.8}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-641.0, -713.0, -650.0, -686.0, -587.0, -596.0, -713.0, -632.0, -533.0, -767.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-641.0, -713.0, -650.0, -686.0, -587.0, -596.0, -713.0, -632.0, -533.0, -767.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.07830056431454695, 'mean_inference_ms': 0.27205470941204524, 'mean_action_processing_ms': 0.030799753240479632, 'mean_env_wait_ms': 0.015995337223323837, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.003554821014404297, 'StateBufferConnector_ms': 0.0011467933654785156, 'ViewRequirementAgentConnector_ms': 0.027277469635009766}, 'num_episodes': 10, 'episode_return_max': -533.0, 'episode_return_min': -767.0, 'episode_return_mean': -651.8, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 2000, 'num_env_steps_sampled_this_iter': 2000, 'timesteps_this_iter': 2000, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.32824548996424163, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.8898420856845, 'policy_loss': -0.05239639969177103, 'vf_loss': 9.93870811257311, 'vf_explained_var': -0.0006001301991042271, 'kl': 0.017651775282047533, 'entropy': 1.712209798443702, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 2325.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000, 'num_env_steps_sampled_for_evaluation_this_iter': 2000}, 'env_runners': {'episode_reward_max': -36.0, 'episode_reward_min': -857.0, 'episode_reward_mean': -716.9333333333333, 'episode_len_mean': 194.53333333333333, 'episode_media': {}, 'episodes_timesteps_total': 11672, 'policy_reward_min': {'default_policy': -857.0}, 'policy_reward_max': {'default_policy': -36.0}, 'policy_reward_mean': {'default_policy': -716.9333333333333}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-758.0, -830.0, -758.0, -821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0, -803.0, -273.0, -821.0, -857.0, -794.0, -641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0, -704.0, -686.0, -776.0, -533.0, -623.0, -677.0, -749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 123, 200, 200, 200, 200, 200, 200, 139, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 189, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 21, 200, 200, 200, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-758.0, -830.0, -758.0, -821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0, -803.0, -273.0, -821.0, -857.0, -794.0, -641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0, -704.0, -686.0, -776.0, -533.0, -623.0, -677.0, -749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08740630484842565, 'mean_inference_ms': 0.27469551262775166, 'mean_action_processing_ms': 0.03138003016586409, 'mean_env_wait_ms': 0.016166942814762515, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.003922780354817708, 'StateBufferConnector_ms': 0.0011638800303141277, 'ViewRequirementAgentConnector_ms': 0.027857224146525066}, 'num_episodes': 20, 'episode_return_max': -36.0, 'episode_return_min': -857.0, 'episode_return_mean': -716.9333333333333, 'episodes_this_iter': 20}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 1164.8454084595835, 'num_env_steps_trained_throughput_per_sec': 1164.8454084595835, 'timesteps_total': 12000, 'num_env_steps_sampled_lifetime': 12000, 'num_agent_steps_sampled_lifetime': 12000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 12000, 'timers': {'training_iteration_time_ms': 3401.416, 'restore_workers_time_ms': 0.006, 'training_step_time_ms': 3401.4, 'sample_time_ms': 847.861, 'load_time_ms': 0.933, 'load_throughput': 4285732.97, 'learn_time_ms': 2549.45, 'learn_throughput': 1568.966, 'synch_weights_time_ms': 2.976, 'restore_eval_workers_time_ms': 0.005, 'evaluation_iteration_time_ms': 792.181, 'evaluation_iteration_throughput': 2482.597}, 'counters': {'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000, 'num_env_steps_sampled_for_evaluation_this_iter': 2000}, 'done': False, 'training_iteration': 3, 'trial_id': 'default', 'date': '2024-11-04_22-18-10', 'timestamp': 1730776690, 'time_this_iter_s': 4.259108066558838, 'time_total_s': 12.586257934570312, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 12.586257934570312, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 36.5, 'ram_util_percent': 55.28333333333334}}\n",
      "{'evaluation': {'env_runners': {'episode_reward_max': -308.0, 'episode_reward_min': -659.0, 'episode_reward_mean': -561.8, 'episode_len_mean': 195.8, 'episode_media': {}, 'episodes_timesteps_total': 1958, 'policy_reward_min': {'default_policy': -659.0}, 'policy_reward_max': {'default_policy': -308.0}, 'policy_reward_mean': {'default_policy': -561.8}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-308.0, -515.0, -659.0, -578.0, -632.0, -632.0, -569.0, -632.0, -506.0, -587.0], 'episode_lengths': [158, 200, 200, 200, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-308.0, -515.0, -659.0, -578.0, -632.0, -632.0, -569.0, -632.0, -506.0, -587.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.07861041889222223, 'mean_inference_ms': 0.2730760065892496, 'mean_action_processing_ms': 0.030894636849984513, 'mean_env_wait_ms': 0.016046580596042356, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0034880638122558594, 'StateBufferConnector_ms': 0.0010418891906738281, 'ViewRequirementAgentConnector_ms': 0.026683807373046875}, 'num_episodes': 10, 'episode_return_max': -308.0, 'episode_return_min': -659.0, 'episode_return_mean': -561.8, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 1958, 'num_env_steps_sampled_this_iter': 1958, 'timesteps_this_iter': 1958, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.40706840711896136, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.845699652805123, 'policy_loss': -0.04156903889761256, 'vf_loss': 9.88419292408933, 'vf_explained_var': 0.00023436950099083685, 'kl': 0.015378785434726587, 'entropy': 1.6678070657996722, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 3255.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000, 'num_env_steps_sampled_for_evaluation_this_iter': 1958}, 'env_runners': {'episode_reward_max': -36.0, 'episode_reward_min': -857.0, 'episode_reward_mean': -682.2439024390244, 'episode_len_mean': 192.21951219512195, 'episode_media': {}, 'episodes_timesteps_total': 15762, 'policy_reward_min': {'default_policy': -857.0}, 'policy_reward_max': {'default_policy': -36.0}, 'policy_reward_mean': {'default_policy': -682.2439024390244}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-758.0, -830.0, -758.0, -821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0, -803.0, -273.0, -821.0, -857.0, -794.0, -641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0, -704.0, -686.0, -776.0, -533.0, -623.0, -677.0, -749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0, -677.0, -152.0, -695.0, -659.0, -515.0, -605.0, -641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 123, 200, 200, 200, 200, 200, 200, 139, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 189, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 21, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 56, 200, 200, 200, 200, 200, 88, 146, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-758.0, -830.0, -758.0, -821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0, -803.0, -273.0, -821.0, -857.0, -794.0, -641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0, -704.0, -686.0, -776.0, -533.0, -623.0, -677.0, -749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0, -677.0, -152.0, -695.0, -659.0, -515.0, -605.0, -641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08756971328484393, 'mean_inference_ms': 0.27515040376405125, 'mean_action_processing_ms': 0.03141072216667178, 'mean_env_wait_ms': 0.016202243747795803, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0038754649278594224, 'StateBufferConnector_ms': 0.0011877315800364425, 'ViewRequirementAgentConnector_ms': 0.027996156273818597}, 'num_episodes': 22, 'episode_return_max': -36.0, 'episode_return_min': -857.0, 'episode_return_mean': -682.2439024390244, 'episodes_this_iter': 22}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 1196.5307687095935, 'num_env_steps_trained_throughput_per_sec': 1196.5307687095935, 'timesteps_total': 16000, 'num_env_steps_sampled_lifetime': 16000, 'num_agent_steps_sampled_lifetime': 16000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 16000, 'timers': {'training_iteration_time_ms': 3386.813, 'restore_workers_time_ms': 0.006, 'training_step_time_ms': 3386.797, 'sample_time_ms': 852.324, 'load_time_ms': 1.022, 'load_throughput': 3914879.477, 'learn_time_ms': 2530.143, 'learn_throughput': 1580.938, 'synch_weights_time_ms': 3.125, 'restore_eval_workers_time_ms': 0.004, 'evaluation_iteration_time_ms': 794.159, 'evaluation_iteration_throughput': 2473.685}, 'counters': {'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000, 'num_env_steps_sampled_for_evaluation_this_iter': 1958}, 'done': False, 'training_iteration': 4, 'trial_id': 'default', 'date': '2024-11-04_22-18-14', 'timestamp': 1730776694, 'time_this_iter_s': 4.145565986633301, 'time_total_s': 16.731823921203613, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 16.731823921203613, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 43.71666666666667, 'ram_util_percent': 55.383333333333326}}\n",
      "{'evaluation': {'env_runners': {'episode_reward_max': -267.0, 'episode_reward_min': -902.0, 'episode_reward_mean': -545.2, 'episode_len_mean': 187.9, 'episode_media': {}, 'episodes_timesteps_total': 1879, 'policy_reward_min': {'default_policy': -902.0}, 'policy_reward_max': {'default_policy': -267.0}, 'policy_reward_mean': {'default_policy': -545.2}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-902.0, -713.0, -444.0, -560.0, -425.0, -479.0, -560.0, -578.0, -267.0, -524.0], 'episode_lengths': [200, 200, 186, 200, 200, 176, 200, 200, 117, 200], 'policy_default_policy_reward': [-902.0, -713.0, -444.0, -560.0, -425.0, -479.0, -560.0, -578.0, -267.0, -524.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.07914600736626268, 'mean_inference_ms': 0.2747220801092757, 'mean_action_processing_ms': 0.03116959344437294, 'mean_env_wait_ms': 0.01627452859743392, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00370025634765625, 'StateBufferConnector_ms': 0.0012445449829101562, 'ViewRequirementAgentConnector_ms': 0.028688907623291016}, 'num_episodes': 10, 'episode_return_max': -267.0, 'episode_return_min': -902.0, 'episode_return_mean': -545.2, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 1879, 'num_env_steps_sampled_this_iter': 1879, 'timesteps_this_iter': 1879, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.5383031223089464, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.813862264284523, 'policy_loss': -0.04846080587075282, 'vf_loss': 9.859222863310126, 'vf_explained_var': 0.0030074934805593184, 'kl': 0.015501119828772312, 'entropy': 1.6328677859357608, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 4185.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled_for_evaluation_this_iter': 1879}, 'env_runners': {'episode_reward_max': -36.0, 'episode_reward_min': -857.0, 'episode_reward_mean': -656.01, 'episode_len_mean': 191.1, 'episode_media': {}, 'episodes_timesteps_total': 19110, 'policy_reward_min': {'default_policy': -857.0}, 'policy_reward_max': {'default_policy': -36.0}, 'policy_reward_mean': {'default_policy': -656.01}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0, -803.0, -273.0, -821.0, -857.0, -794.0, -641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0, -704.0, -686.0, -776.0, -533.0, -623.0, -677.0, -749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0, -677.0, -152.0, -695.0, -659.0, -515.0, -605.0, -641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0, -704.0, -794.0, -641.0, -224.0, -785.0, -357.0, -650.0, -578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 123, 200, 200, 200, 200, 200, 200, 139, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 189, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 21, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 56, 200, 200, 200, 200, 200, 88, 146, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 101, 200, 153, 200, 200, 200, 200, 200, 200, 200, 200, 200, 94, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-821.0, -839.0, -857.0, -722.0, -857.0, -812.0, -794.0, -659.0, -794.0, -767.0, -713.0, -767.0, -794.0, -812.0, -722.0, -821.0, -848.0, -803.0, -273.0, -821.0, -857.0, -794.0, -641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0, -704.0, -686.0, -776.0, -533.0, -623.0, -677.0, -749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0, -677.0, -152.0, -695.0, -659.0, -515.0, -605.0, -641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0, -704.0, -794.0, -641.0, -224.0, -785.0, -357.0, -650.0, -578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08777451246638224, 'mean_inference_ms': 0.2757753653370525, 'mean_action_processing_ms': 0.0315023301603995, 'mean_env_wait_ms': 0.01625152303897934, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00388336181640625, 'StateBufferConnector_ms': 0.0011878013610839844, 'ViewRequirementAgentConnector_ms': 0.028214693069458008}, 'num_episodes': 21, 'episode_return_max': -36.0, 'episode_return_min': -857.0, 'episode_return_mean': -656.01, 'episodes_this_iter': 21}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 959.3002235974982, 'num_env_steps_trained_throughput_per_sec': 959.3002235974982, 'timesteps_total': 20000, 'num_env_steps_sampled_lifetime': 20000, 'num_agent_steps_sampled_lifetime': 20000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 20000, 'timers': {'training_iteration_time_ms': 3543.392, 'restore_workers_time_ms': 0.006, 'training_step_time_ms': 3543.377, 'sample_time_ms': 857.674, 'load_time_ms': 1.05, 'load_throughput': 3810924.95, 'learn_time_ms': 2681.327, 'learn_throughput': 1491.799, 'synch_weights_time_ms': 3.137, 'restore_eval_workers_time_ms': 0.005, 'evaluation_iteration_time_ms': 792.499, 'evaluation_iteration_throughput': 2457.29}, 'counters': {'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled_for_evaluation_this_iter': 1879}, 'done': False, 'training_iteration': 5, 'trial_id': 'default', 'date': '2024-11-04_22-18-19', 'timestamp': 1730776699, 'time_this_iter_s': 4.957963943481445, 'time_total_s': 21.68978786468506, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 21.68978786468506, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 45.41428571428571, 'ram_util_percent': 55.48571428571428}}\n",
      "{'evaluation': {'env_runners': {'episode_reward_max': -68.0, 'episode_reward_min': -695.0, 'episode_reward_mean': -467.0, 'episode_len_mean': 176.9, 'episode_media': {}, 'episodes_timesteps_total': 1769, 'policy_reward_min': {'default_policy': -695.0}, 'policy_reward_max': {'default_policy': -68.0}, 'policy_reward_mean': {'default_policy': -467.0}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-68.0, -524.0, -479.0, -488.0, -497.0, -275.0, -407.0, -695.0, -686.0, -551.0], 'episode_lengths': [35, 200, 200, 200, 200, 134, 200, 200, 200, 200], 'policy_default_policy_reward': [-68.0, -524.0, -479.0, -488.0, -497.0, -275.0, -407.0, -695.0, -686.0, -551.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.07982911663299079, 'mean_inference_ms': 0.2771441627980481, 'mean_action_processing_ms': 0.031477882661734104, 'mean_env_wait_ms': 0.016510968329728898, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.003521442413330078, 'StateBufferConnector_ms': 0.0011444091796875, 'ViewRequirementAgentConnector_ms': 0.027811527252197266}, 'num_episodes': 10, 'episode_return_max': -68.0, 'episode_return_min': -695.0, 'episode_return_mean': -467.0, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 1769, 'num_env_steps_sampled_this_iter': 1769, 'timesteps_this_iter': 1769, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.5453243297034054, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.82287631598852, 'policy_loss': -0.047944785350613216, 'vf_loss': 9.867322636676091, 'vf_explained_var': 0.00034286950224189346, 'kl': 0.01749218666327808, 'entropy': 1.5825123376743768, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 5115.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000, 'num_env_steps_sampled_for_evaluation_this_iter': 1769}, 'env_runners': {'episode_reward_max': -36.0, 'episode_reward_min': -812.0, 'episode_reward_mean': -604.56, 'episode_len_mean': 189.81, 'episode_media': {}, 'episodes_timesteps_total': 18981, 'policy_reward_min': {'default_policy': -812.0}, 'policy_reward_max': {'default_policy': -36.0}, 'policy_reward_mean': {'default_policy': -604.56}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0, -704.0, -686.0, -776.0, -533.0, -623.0, -677.0, -749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0, -677.0, -152.0, -695.0, -659.0, -515.0, -605.0, -641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0, -704.0, -794.0, -641.0, -224.0, -785.0, -357.0, -650.0, -578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0, -605.0, -198.0, -686.0, -569.0, -587.0, -542.0, -650.0, -596.0, -623.0, -542.0, -506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0], 'episode_lengths': [200, 200, 200, 139, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 189, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 21, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 56, 200, 200, 200, 200, 200, 88, 146, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 101, 200, 153, 200, 200, 200, 200, 200, 200, 200, 200, 200, 94, 200, 200, 200, 200, 200, 200, 84, 200, 200, 200, 200, 200, 200, 200, 200, 200, 110, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-641.0, -731.0, -785.0, -442.0, -695.0, -722.0, -767.0, -794.0, -677.0, -812.0, -677.0, -695.0, -812.0, -641.0, -645.0, -704.0, -686.0, -776.0, -533.0, -623.0, -677.0, -749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0, -677.0, -152.0, -695.0, -659.0, -515.0, -605.0, -641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0, -704.0, -794.0, -641.0, -224.0, -785.0, -357.0, -650.0, -578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0, -605.0, -198.0, -686.0, -569.0, -587.0, -542.0, -650.0, -596.0, -623.0, -542.0, -506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08808638678756811, 'mean_inference_ms': 0.27674695314634334, 'mean_action_processing_ms': 0.031614174724055435, 'mean_env_wait_ms': 0.016332679376387896, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.003916740417480469, 'StateBufferConnector_ms': 0.0011990070343017578, 'ViewRequirementAgentConnector_ms': 0.02866053581237793}, 'num_episodes': 22, 'episode_return_max': -36.0, 'episode_return_min': -812.0, 'episode_return_mean': -604.56, 'episodes_this_iter': 22}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000, 'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 1016.9795266478, 'num_env_steps_trained_throughput_per_sec': 1016.9795266478, 'timesteps_total': 24000, 'num_env_steps_sampled_lifetime': 24000, 'num_agent_steps_sampled_lifetime': 24000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 24000, 'timers': {'training_iteration_time_ms': 3608.364, 'restore_workers_time_ms': 0.006, 'training_step_time_ms': 3608.348, 'sample_time_ms': 861.424, 'load_time_ms': 1.152, 'load_throughput': 3473663.549, 'learn_time_ms': 2742.379, 'learn_throughput': 1458.588, 'synch_weights_time_ms': 3.201, 'restore_eval_workers_time_ms': 0.004, 'evaluation_iteration_time_ms': 787.453, 'evaluation_iteration_throughput': 2435.278}, 'counters': {'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000, 'num_env_steps_sampled_for_evaluation_this_iter': 1769}, 'done': False, 'training_iteration': 6, 'trial_id': 'default', 'date': '2024-11-04_22-18-23', 'timestamp': 1730776703, 'time_this_iter_s': 4.698491811752319, 'time_total_s': 26.388279676437378, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 26.388279676437378, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 35.08571428571429, 'ram_util_percent': 55.51428571428572}}\n",
      "{'evaluation': {'env_runners': {'episode_reward_max': -225.0, 'episode_reward_min': -812.0, 'episode_reward_mean': -449.3, 'episode_len_mean': 188.9, 'episode_media': {}, 'episodes_timesteps_total': 1889, 'policy_reward_min': {'default_policy': -812.0}, 'policy_reward_max': {'default_policy': -225.0}, 'policy_reward_mean': {'default_policy': -449.3}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-443.0, -335.0, -454.0, -380.0, -407.0, -596.0, -371.0, -470.0, -812.0, -225.0], 'episode_lengths': [200, 200, 178, 200, 200, 200, 200, 200, 200, 111], 'policy_default_policy_reward': [-443.0, -335.0, -454.0, -380.0, -407.0, -596.0, -371.0, -470.0, -812.0, -225.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08015819149752025, 'mean_inference_ms': 0.27814378450791777, 'mean_action_processing_ms': 0.03166494528974623, 'mean_env_wait_ms': 0.016651533724265727, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0038385391235351562, 'StateBufferConnector_ms': 0.0012063980102539062, 'ViewRequirementAgentConnector_ms': 0.029137134552001953}, 'num_episodes': 10, 'episode_return_max': -225.0, 'episode_return_min': -812.0, 'episode_return_mean': -449.3, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 1889, 'num_env_steps_sampled_this_iter': 1889, 'timesteps_this_iter': 1889, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.6194529446542903, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.813817947141585, 'policy_loss': -0.04847891826823514, 'vf_loss': 9.858692801895963, 'vf_explained_var': -0.00010468466307527275, 'kl': 0.018020302198086768, 'entropy': 1.533134796414324, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 6045.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000, 'num_env_steps_sampled_for_evaluation_this_iter': 1889}, 'env_runners': {'episode_reward_max': -36.0, 'episode_reward_min': -803.0, 'episode_reward_mean': -565.91, 'episode_len_mean': 188.54, 'episode_media': {}, 'episodes_timesteps_total': 18854, 'policy_reward_min': {'default_policy': -803.0}, 'policy_reward_max': {'default_policy': -36.0}, 'policy_reward_mean': {'default_policy': -565.91}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0, -677.0, -152.0, -695.0, -659.0, -515.0, -605.0, -641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0, -704.0, -794.0, -641.0, -224.0, -785.0, -357.0, -650.0, -578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0, -605.0, -198.0, -686.0, -569.0, -587.0, -542.0, -650.0, -596.0, -623.0, -542.0, -506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0, -542.0, -587.0, -587.0, -407.0, -713.0, -524.0, -578.0, -470.0, -524.0, -470.0, -497.0, -515.0, -479.0, -490.0, -569.0, -260.0, -416.0, -758.0, -587.0, -407.0, -290.0], 'episode_lengths': [200, 200, 200, 200, 21, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 56, 200, 200, 200, 200, 200, 88, 146, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 101, 200, 153, 200, 200, 200, 200, 200, 200, 200, 200, 200, 94, 200, 200, 200, 200, 200, 200, 84, 200, 200, 200, 200, 200, 200, 200, 200, 200, 110, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 187, 200, 92, 200, 200, 200, 200, 122], 'policy_default_policy_reward': [-749.0, -803.0, -686.0, -695.0, -36.0, -776.0, -623.0, -803.0, -668.0, -722.0, -668.0, -488.0, -677.0, -794.0, -677.0, -152.0, -695.0, -659.0, -515.0, -605.0, -641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0, -704.0, -794.0, -641.0, -224.0, -785.0, -357.0, -650.0, -578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0, -605.0, -198.0, -686.0, -569.0, -587.0, -542.0, -650.0, -596.0, -623.0, -542.0, -506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0, -542.0, -587.0, -587.0, -407.0, -713.0, -524.0, -578.0, -470.0, -524.0, -470.0, -497.0, -515.0, -479.0, -490.0, -569.0, -260.0, -416.0, -758.0, -587.0, -407.0, -290.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08843546859716624, 'mean_inference_ms': 0.2778270605206342, 'mean_action_processing_ms': 0.03175630077466558, 'mean_env_wait_ms': 0.016424385213824347, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0038576126098632812, 'StateBufferConnector_ms': 0.0012054443359375, 'ViewRequirementAgentConnector_ms': 0.028837919235229492}, 'num_episodes': 21, 'episode_return_max': -36.0, 'episode_return_min': -803.0, 'episode_return_mean': -565.91, 'episodes_this_iter': 21}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000, 'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 1022.7107502541656, 'num_env_steps_trained_throughput_per_sec': 1022.7107502541656, 'timesteps_total': 28000, 'num_env_steps_sampled_lifetime': 28000, 'num_agent_steps_sampled_lifetime': 28000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 28000, 'timers': {'training_iteration_time_ms': 3651.623, 'restore_workers_time_ms': 0.006, 'training_step_time_ms': 3651.608, 'sample_time_ms': 864.509, 'load_time_ms': 1.227, 'load_throughput': 3259972.575, 'learn_time_ms': 2782.437, 'learn_throughput': 1437.589, 'synch_weights_time_ms': 3.242, 'restore_eval_workers_time_ms': 0.004, 'evaluation_iteration_time_ms': 788.84, 'evaluation_iteration_throughput': 2425.805}, 'counters': {'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000, 'num_env_steps_sampled_for_evaluation_this_iter': 1889}, 'done': False, 'training_iteration': 7, 'trial_id': 'default', 'date': '2024-11-04_22-18-28', 'timestamp': 1730776708, 'time_this_iter_s': 4.7105326652526855, 'time_total_s': 31.098812341690063, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 31.098812341690063, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 38.614285714285714, 'ram_util_percent': 55.528571428571425}}\n",
      "{'evaluation': {'env_runners': {'episode_reward_max': 5.0, 'episode_reward_min': -677.0, 'episode_reward_mean': -413.0, 'episode_len_mean': 170.0, 'episode_media': {}, 'episodes_timesteps_total': 1700, 'policy_reward_min': {'default_policy': -677.0}, 'policy_reward_max': {'default_policy': 5.0}, 'policy_reward_mean': {'default_policy': -413.0}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-470.0, -294.0, -677.0, -335.0, -299.0, -587.0, -470.0, -434.0, -569.0, 5.0], 'episode_lengths': [200, 126, 200, 200, 158, 200, 200, 200, 200, 16], 'policy_default_policy_reward': [-470.0, -294.0, -677.0, -335.0, -299.0, -587.0, -470.0, -434.0, -569.0, 5.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08050842328114552, 'mean_inference_ms': 0.2789697321117019, 'mean_action_processing_ms': 0.03178832261854212, 'mean_env_wait_ms': 0.01673884472647355, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00354766845703125, 'StateBufferConnector_ms': 0.0012493133544921875, 'ViewRequirementAgentConnector_ms': 0.027484893798828125}, 'num_episodes': 10, 'episode_return_max': 5.0, 'episode_return_min': -677.0, 'episode_return_mean': -413.0, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 1700, 'num_env_steps_sampled_this_iter': 1700, 'timesteps_this_iter': 1700, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.6926168144390147, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.80274434243479, 'policy_loss': -0.0457771610198242, 'vf_loss': 9.844863494749992, 'vf_explained_var': -0.0016905036023868026, 'kl': 0.01829012641733592, 'entropy': 1.4863410005005457, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 6975.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000, 'num_env_steps_sampled_for_evaluation_this_iter': 1700}, 'env_runners': {'episode_reward_max': -198.0, 'episode_reward_min': -866.0, 'episode_reward_mean': -535.26, 'episode_len_mean': 190.41, 'episode_media': {}, 'episodes_timesteps_total': 19041, 'policy_reward_min': {'default_policy': -866.0}, 'policy_reward_max': {'default_policy': -198.0}, 'policy_reward_mean': {'default_policy': -535.26}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0, -704.0, -794.0, -641.0, -224.0, -785.0, -357.0, -650.0, -578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0, -605.0, -198.0, -686.0, -569.0, -587.0, -542.0, -650.0, -596.0, -623.0, -542.0, -506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0, -542.0, -587.0, -587.0, -407.0, -713.0, -524.0, -578.0, -470.0, -524.0, -470.0, -497.0, -515.0, -479.0, -490.0, -569.0, -260.0, -416.0, -758.0, -587.0, -407.0, -290.0, -524.0, -866.0, -362.0, -497.0, -527.0, -551.0, -434.0, -488.0, -284.0, -380.0, -389.0, -479.0, -515.0, -452.0, -274.0, -443.0, -479.0, -407.0, -515.0, -560.0], 'episode_lengths': [200, 88, 146, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 101, 200, 153, 200, 200, 200, 200, 200, 200, 200, 200, 200, 94, 200, 200, 200, 200, 200, 200, 84, 200, 200, 200, 200, 200, 200, 200, 200, 200, 110, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 187, 200, 92, 200, 200, 200, 200, 122, 200, 200, 200, 200, 188, 200, 200, 200, 161, 200, 200, 200, 200, 200, 115, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-641.0, -238.0, -440.0, -551.0, -605.0, -668.0, -794.0, -740.0, -614.0, -650.0, -614.0, -641.0, -659.0, -560.0, -578.0, -632.0, -704.0, -794.0, -641.0, -224.0, -785.0, -357.0, -650.0, -578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0, -605.0, -198.0, -686.0, -569.0, -587.0, -542.0, -650.0, -596.0, -623.0, -542.0, -506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0, -542.0, -587.0, -587.0, -407.0, -713.0, -524.0, -578.0, -470.0, -524.0, -470.0, -497.0, -515.0, -479.0, -490.0, -569.0, -260.0, -416.0, -758.0, -587.0, -407.0, -290.0, -524.0, -866.0, -362.0, -497.0, -527.0, -551.0, -434.0, -488.0, -284.0, -380.0, -389.0, -479.0, -515.0, -452.0, -274.0, -443.0, -479.0, -407.0, -515.0, -560.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08877474730126914, 'mean_inference_ms': 0.27885198984620757, 'mean_action_processing_ms': 0.031894093753820345, 'mean_env_wait_ms': 0.016523960537138255, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0038487911224365234, 'StateBufferConnector_ms': 0.0012111663818359375, 'ViewRequirementAgentConnector_ms': 0.02893662452697754}, 'num_episodes': 20, 'episode_return_max': -198.0, 'episode_return_min': -866.0, 'episode_return_mean': -535.26, 'episodes_this_iter': 20}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000, 'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 999.8100164930474, 'num_env_steps_trained_throughput_per_sec': 999.8100164930474, 'timesteps_total': 32000, 'num_env_steps_sampled_lifetime': 32000, 'num_agent_steps_sampled_lifetime': 32000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 32000, 'timers': {'training_iteration_time_ms': 3695.266, 'restore_workers_time_ms': 0.006, 'training_step_time_ms': 3695.25, 'sample_time_ms': 866.399, 'load_time_ms': 1.319, 'load_throughput': 3032004.157, 'learn_time_ms': 2824.034, 'learn_throughput': 1416.413, 'synch_weights_time_ms': 3.309, 'restore_eval_workers_time_ms': 0.004, 'evaluation_iteration_time_ms': 780.484, 'evaluation_iteration_throughput': 2417.569}, 'counters': {'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000, 'num_env_steps_sampled_for_evaluation_this_iter': 1700}, 'done': False, 'training_iteration': 8, 'trial_id': 'default', 'date': '2024-11-04_22-18-33', 'timestamp': 1730776713, 'time_this_iter_s': 4.725131988525391, 'time_total_s': 35.823944330215454, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 35.823944330215454, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 45.714285714285715, 'ram_util_percent': 55.442857142857136}}\n",
      "{'evaluation': {'env_runners': {'episode_reward_max': -260.0, 'episode_reward_min': -479.0, 'episode_reward_mean': -368.3, 'episode_len_mean': 188.0, 'episode_media': {}, 'episodes_timesteps_total': 1880, 'policy_reward_min': {'default_policy': -479.0}, 'policy_reward_max': {'default_policy': -260.0}, 'policy_reward_mean': {'default_policy': -368.3}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-299.0, -425.0, -443.0, -479.0, -479.0, -281.0, -284.0, -260.0, -299.0, -434.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 134, 146, 200, 200], 'policy_default_policy_reward': [-299.0, -425.0, -443.0, -479.0, -479.0, -281.0, -284.0, -260.0, -299.0, -434.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08064803371555282, 'mean_inference_ms': 0.2791740133670228, 'mean_action_processing_ms': 0.03184448369374037, 'mean_env_wait_ms': 0.01678533648455851, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.003936290740966797, 'StateBufferConnector_ms': 0.0011277198791503906, 'ViewRequirementAgentConnector_ms': 0.028705596923828125}, 'num_episodes': 10, 'episode_return_max': -260.0, 'episode_return_min': -479.0, 'episode_return_mean': -368.3, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 1880, 'num_env_steps_sampled_this_iter': 1880, 'timesteps_this_iter': 1880, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7563514884521243, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.774184909943612, 'policy_loss': -0.047834581012026436, 'vf_loss': 9.818213833019298, 'vf_explained_var': 0.0007507736964892316, 'kl': 0.019028310096409106, 'entropy': 1.4242403050904633, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 7905.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000, 'num_env_steps_sampled_for_evaluation_this_iter': 1880}, 'env_runners': {'episode_reward_max': -155.0, 'episode_reward_min': -866.0, 'episode_reward_mean': -490.94, 'episode_len_mean': 187.94, 'episode_media': {}, 'episodes_timesteps_total': 18794, 'policy_reward_min': {'default_policy': -866.0}, 'policy_reward_max': {'default_policy': -155.0}, 'policy_reward_mean': {'default_policy': -490.94}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0, -605.0, -198.0, -686.0, -569.0, -587.0, -542.0, -650.0, -596.0, -623.0, -542.0, -506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0, -542.0, -587.0, -587.0, -407.0, -713.0, -524.0, -578.0, -470.0, -524.0, -470.0, -497.0, -515.0, -479.0, -490.0, -569.0, -260.0, -416.0, -758.0, -587.0, -407.0, -290.0, -524.0, -866.0, -362.0, -497.0, -527.0, -551.0, -434.0, -488.0, -284.0, -380.0, -389.0, -479.0, -515.0, -452.0, -274.0, -443.0, -479.0, -407.0, -515.0, -560.0, -353.0, -380.0, -329.0, -270.0, -332.0, -641.0, -461.0, -452.0, -206.0, -434.0, -677.0, -362.0, -632.0, -380.0, -155.0, -389.0, -362.0, -223.0, -313.0, -524.0, -452.0, -551.0, -470.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 94, 200, 200, 200, 200, 200, 200, 84, 200, 200, 200, 200, 200, 200, 200, 200, 200, 110, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 187, 200, 92, 200, 200, 200, 200, 122, 200, 200, 200, 200, 188, 200, 200, 200, 161, 200, 200, 200, 200, 200, 115, 200, 200, 200, 200, 200, 200, 200, 161, 156, 146, 200, 200, 200, 74, 200, 200, 200, 200, 200, 68, 200, 200, 118, 118, 200, 200, 200, 200], 'policy_default_policy_reward': [-578.0, -641.0, -533.0, -749.0, -668.0, -569.0, -569.0, -587.0, -253.0, -641.0, -542.0, -497.0, -551.0, -470.0, -605.0, -198.0, -686.0, -569.0, -587.0, -542.0, -650.0, -596.0, -623.0, -542.0, -506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0, -542.0, -587.0, -587.0, -407.0, -713.0, -524.0, -578.0, -470.0, -524.0, -470.0, -497.0, -515.0, -479.0, -490.0, -569.0, -260.0, -416.0, -758.0, -587.0, -407.0, -290.0, -524.0, -866.0, -362.0, -497.0, -527.0, -551.0, -434.0, -488.0, -284.0, -380.0, -389.0, -479.0, -515.0, -452.0, -274.0, -443.0, -479.0, -407.0, -515.0, -560.0, -353.0, -380.0, -329.0, -270.0, -332.0, -641.0, -461.0, -452.0, -206.0, -434.0, -677.0, -362.0, -632.0, -380.0, -155.0, -389.0, -362.0, -223.0, -313.0, -524.0, -452.0, -551.0, -470.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08911612371160985, 'mean_inference_ms': 0.2799944447944611, 'mean_action_processing_ms': 0.03206783614360213, 'mean_env_wait_ms': 0.016628461974547912, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.003900766372680664, 'StateBufferConnector_ms': 0.0012145042419433594, 'ViewRequirementAgentConnector_ms': 0.02890467643737793}, 'num_episodes': 23, 'episode_return_max': -155.0, 'episode_return_min': -866.0, 'episode_return_mean': -490.94, 'episodes_this_iter': 23}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000, 'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 1015.0429153675531, 'num_env_steps_trained_throughput_per_sec': 1015.0429153675531, 'timesteps_total': 36000, 'num_env_steps_sampled_lifetime': 36000, 'num_agent_steps_sampled_lifetime': 36000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 36000, 'timers': {'training_iteration_time_ms': 3722.539, 'restore_workers_time_ms': 0.006, 'training_step_time_ms': 3722.522, 'sample_time_ms': 869.663, 'load_time_ms': 1.334, 'load_throughput': 2998727.861, 'learn_time_ms': 2848.061, 'learn_throughput': 1404.464, 'synch_weights_time_ms': 3.277, 'restore_eval_workers_time_ms': 0.004, 'evaluation_iteration_time_ms': 780.953, 'evaluation_iteration_throughput': 2415.141}, 'counters': {'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000, 'num_env_steps_sampled_for_evaluation_this_iter': 1880}, 'done': False, 'training_iteration': 9, 'trial_id': 'default', 'date': '2024-11-04_22-18-38', 'timestamp': 1730776718, 'time_this_iter_s': 4.728063106536865, 'time_total_s': 40.55200743675232, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 40.55200743675232, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 24.666666666666668, 'ram_util_percent': 55.383333333333326}}\n",
      "{'evaluation': {'env_runners': {'episode_reward_max': -43.0, 'episode_reward_min': -497.0, 'episode_reward_mean': -345.1, 'episode_len_mean': 172.3, 'episode_media': {}, 'episodes_timesteps_total': 1723, 'policy_reward_min': {'default_policy': -497.0}, 'policy_reward_max': {'default_policy': -43.0}, 'policy_reward_mean': {'default_policy': -345.1}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-407.0, -497.0, -380.0, -43.0, -380.0, -407.0, -343.0, -326.0, -452.0, -216.0], 'episode_lengths': [200, 200, 200, 37, 200, 200, 166, 200, 200, 120], 'policy_default_policy_reward': [-407.0, -497.0, -380.0, -43.0, -380.0, -407.0, -343.0, -326.0, -452.0, -216.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08078711358893587, 'mean_inference_ms': 0.2794017497980249, 'mean_action_processing_ms': 0.03189308463943802, 'mean_env_wait_ms': 0.01681680392183666, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.003879070281982422, 'StateBufferConnector_ms': 0.0012874603271484375, 'ViewRequirementAgentConnector_ms': 0.029168128967285156}, 'num_episodes': 10, 'episode_return_max': -43.0, 'episode_return_min': -497.0, 'episode_return_mean': -345.1, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 1723, 'num_env_steps_sampled_this_iter': 1723, 'timesteps_this_iter': 1723, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8183289239403381, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.7112320182144, 'policy_loss': -0.03583189535445423, 'vf_loss': 9.743620075718049, 'vf_explained_var': 0.0021045434218581005, 'kl': 0.017219352831641718, 'entropy': 1.3580683847909332, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 8835.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled_for_evaluation_this_iter': 1723}, 'env_runners': {'episode_reward_max': -28.0, 'episode_reward_min': -866.0, 'episode_reward_mean': -435.22, 'episode_len_mean': 181.99, 'episode_media': {}, 'episodes_timesteps_total': 18199, 'policy_reward_min': {'default_policy': -866.0}, 'policy_reward_max': {'default_policy': -28.0}, 'policy_reward_mean': {'default_policy': -435.22}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0, -542.0, -587.0, -587.0, -407.0, -713.0, -524.0, -578.0, -470.0, -524.0, -470.0, -497.0, -515.0, -479.0, -490.0, -569.0, -260.0, -416.0, -758.0, -587.0, -407.0, -290.0, -524.0, -866.0, -362.0, -497.0, -527.0, -551.0, -434.0, -488.0, -284.0, -380.0, -389.0, -479.0, -515.0, -452.0, -274.0, -443.0, -479.0, -407.0, -515.0, -560.0, -353.0, -380.0, -329.0, -270.0, -332.0, -641.0, -461.0, -452.0, -206.0, -434.0, -677.0, -362.0, -632.0, -380.0, -155.0, -389.0, -362.0, -223.0, -313.0, -524.0, -452.0, -551.0, -470.0, -398.0, -353.0, -275.0, -461.0, -28.0, -596.0, -172.0, -353.0, -416.0, -398.0, -326.0, -118.0, -65.0, -353.0, -551.0, -299.0, -191.0, -344.0, -141.0, -596.0, -362.0, -363.0, -362.0, -353.0], 'episode_lengths': [200, 110, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 187, 200, 92, 200, 200, 200, 200, 122, 200, 200, 200, 200, 188, 200, 200, 200, 161, 200, 200, 200, 200, 200, 115, 200, 200, 200, 200, 200, 200, 200, 161, 156, 146, 200, 200, 200, 74, 200, 200, 200, 200, 200, 68, 200, 200, 118, 118, 200, 200, 200, 200, 200, 200, 170, 200, 31, 200, 94, 200, 200, 200, 200, 94, 50, 200, 200, 200, 95, 200, 72, 200, 200, 177, 200, 200], 'policy_default_policy_reward': [-506.0, -215.0, -470.0, -479.0, -731.0, -515.0, -515.0, -497.0, -497.0, -623.0, -704.0, -452.0, -542.0, -587.0, -587.0, -407.0, -713.0, -524.0, -578.0, -470.0, -524.0, -470.0, -497.0, -515.0, -479.0, -490.0, -569.0, -260.0, -416.0, -758.0, -587.0, -407.0, -290.0, -524.0, -866.0, -362.0, -497.0, -527.0, -551.0, -434.0, -488.0, -284.0, -380.0, -389.0, -479.0, -515.0, -452.0, -274.0, -443.0, -479.0, -407.0, -515.0, -560.0, -353.0, -380.0, -329.0, -270.0, -332.0, -641.0, -461.0, -452.0, -206.0, -434.0, -677.0, -362.0, -632.0, -380.0, -155.0, -389.0, -362.0, -223.0, -313.0, -524.0, -452.0, -551.0, -470.0, -398.0, -353.0, -275.0, -461.0, -28.0, -596.0, -172.0, -353.0, -416.0, -398.0, -326.0, -118.0, -65.0, -353.0, -551.0, -299.0, -191.0, -344.0, -141.0, -596.0, -362.0, -363.0, -362.0, -353.0]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.08937418905442264, 'mean_inference_ms': 0.2808798888449192, 'mean_action_processing_ms': 0.03218467213656814, 'mean_env_wait_ms': 0.016709867482256387, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0038802623748779297, 'StateBufferConnector_ms': 0.001222848892211914, 'ViewRequirementAgentConnector_ms': 0.028891801834106445}, 'num_episodes': 24, 'episode_return_max': -28.0, 'episode_return_min': -866.0, 'episode_return_mean': -435.22, 'episodes_this_iter': 24}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 938.9968830540529, 'num_env_steps_trained_throughput_per_sec': 938.9968830540529, 'timesteps_total': 40000, 'num_env_steps_sampled_lifetime': 40000, 'num_agent_steps_sampled_lifetime': 40000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 40000, 'timers': {'training_iteration_time_ms': 3776.272, 'restore_workers_time_ms': 0.006, 'training_step_time_ms': 3776.256, 'sample_time_ms': 870.341, 'load_time_ms': 1.372, 'load_throughput': 2914785.872, 'learn_time_ms': 2901.09, 'learn_throughput': 1378.792, 'synch_weights_time_ms': 3.265, 'restore_eval_workers_time_ms': 0.004, 'evaluation_iteration_time_ms': 775.107, 'evaluation_iteration_throughput': 2412.312}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled_for_evaluation_this_iter': 1723}, 'done': False, 'training_iteration': 10, 'trial_id': 'default', 'date': '2024-11-04_22-18-43', 'timestamp': 1730776723, 'time_this_iter_s': 4.985154151916504, 'time_total_s': 45.53716158866882, 'pid': 39430, 'hostname': 'Avrils-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x373800540>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 1, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'recreate_failed_env_runners': False, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 45.53716158866882, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 44.699999999999996, 'ram_util_percent': 55.471428571428575}}\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "\n",
    "# Shutdown any existing Ray instances\n",
    "ray.shutdown()\n",
    "\n",
    "# Initialize Ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# Configure the PPO agent\n",
    "config = PPOConfig()\n",
    "config.environment(env=\"Taxi-v3\")\n",
    "config.evaluation(evaluation_interval=1, evaluation_duration=10)\n",
    "\n",
    "# Create a PPO trainer\n",
    "trainer = PPO(config=config)\n",
    "\n",
    "# Train the agent\n",
    "for i in range(10):\n",
    "    result = trainer.train()\n",
    "    file_name = trainer.save(CHECKPOINT_ROOT)\n",
    "    print(result)\n",
    "\n",
    "# Shutdown Ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration:\n",
      "FullyConnectedNetwork(\n",
      "  (_logits): SlimFC(\n",
      "    (_model): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (_hidden_layers): Sequential(\n",
      "    (0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=500, out_features=256, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (1): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_value_branch_separate): Sequential(\n",
      "    (0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=500, out_features=256, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (1): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_value_branch): SlimFC(\n",
      "    (_model): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "policy = trainer.get_policy()\n",
    "model = policy.model\n",
    "print(\"Model configuration:\")\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
